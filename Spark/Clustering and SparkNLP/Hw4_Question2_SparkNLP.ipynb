{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhJsJlJQHz2m",
        "outputId": "24cc8abf-db08-4f97-e9a3-3c2e71d26aa2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-30 14:54:44--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2023-04-30 14:54:45--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-30 14:54:45 (77.8 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.3 and Spark NLP 4.4.1\n",
            "setup Colab for PySpark 3.2.3 and Spark NLP 4.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "STZl_ngcRQ3e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import sparknlp\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
        "! wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"
      ],
      "metadata": {
        "id": "a0BcCbQXRl_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2aeeca8-7fc9-4742-d59e-87d8b5b2329a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-30 13:03:59--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24032125 (23M) [text/plain]\n",
            "Saving to: ‘news_category_train.csv.1’\n",
            "\n",
            "news_category_train 100%[===================>]  22.92M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-04-30 13:03:59 (314 MB/s) - ‘news_category_train.csv.1’ saved [24032125/24032125]\n",
            "\n",
            "--2023-04-30 13:03:59--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1504408 (1.4M) [text/plain]\n",
            "Saving to: ‘news_category_test.csv.1’\n",
            "\n",
            "news_category_test. 100%[===================>]   1.43M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-04-30 13:04:00 (207 MB/s) - ‘news_category_test.csv.1’ saved [1504408/1504408]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start(gpu=True)\n",
        "\n",
        "print(\"Spark NLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Apache Spark version: {}\".format(spark.version))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0KuqqsYVj3n",
        "outputId": "d254a2b0-3cd4-41b0-a1c6-e17791db64ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version: 4.4.1\n",
            "Apache Spark version: 3.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_df = spark.read.option(\"header\", True).csv(\"news_category_train.csv\")\n",
        "raw_test_df = spark.read.option(\"header\", True).csv(\"news_category_test.csv\")"
      ],
      "metadata": {
        "id": "fVdYqb82U1si"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_train_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gxrpE1EV6Ew",
        "outputId": "5d58a206-937e-4715-e76e-1a46707bb040"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+\n",
            "|category|         description|\n",
            "+--------+--------------------+\n",
            "|Business| Short sellers, W...|\n",
            "|Business| Private investme...|\n",
            "|Business| Soaring crude pr...|\n",
            "|Business| Authorities have...|\n",
            "|Business| Tearaway world o...|\n",
            "+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_train_df.groupBy(\"category\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smPJcGaUV6Cu",
        "outputId": "8e26988f-4a71-4551-9f93-5de7be4a3c32"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|   World|30000|\n",
            "|Sci/Tech|30000|\n",
            "|  Sports|30000|\n",
            "|Business|30000|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "raw_test_df.groupBy(\"category\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH0kZj4qV6Ai",
        "outputId": "fd9cc3fe-e06d-4f36-af45-1cbb98ce9771"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|   World| 1900|\n",
            "|Sci/Tech| 1900|\n",
            "|  Sports| 1900|\n",
            "|Business| 1900|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert w/o Preprocessing"
      ],
      "metadata": {
        "id": "B64GPUGTU23u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r /root/annotator_logs"
      ],
      "metadata": {
        "id": "myIKst8NjSt4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "bert_embeddings = BertEmbeddings().pretrained(name='small_bert_L4_256', lang='en') \\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "sentence_embedding = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierDL = ClassifierDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"category\")\\\n",
        "    .setMaxEpochs(5)\\\n",
        "    .setLr(0.001)\\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setVerbose(1)\n",
        "\n",
        "\n",
        "bert_no_processing_pipeline = Pipeline(stages=[document_assembler,\n",
        "                                               tokenizer,\n",
        "                                               bert_embeddings,\n",
        "                                               sentence_embedding,\n",
        "                                               classsifierDL])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ywm6x0EWXfX",
        "outputId": "688f98ef-360c-4b83-b76e-36f082a9406f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_bert_L4_256 download started this may take some time.\n",
            "Approximate size to download 40.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time bert_no_processing_pipeline_model = bert_no_processing_pipeline.fit(raw_train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d47nKxwmWXdO",
        "outputId": "af21ca01-7c08-4d1d-b81a-172bde4abe1f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 s, sys: 209 ms, total: 2.21 s\n",
            "Wall time: 7min 39s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"/root/annotator_logs\")"
      ],
      "metadata": {
        "id": "30hupxTzOPZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_no_processing_pipeline_model.write().overwrite().save('bert_no_processing_tokenized_pipeline_model')"
      ],
      "metadata": {
        "id": "t1qwJm-LShZQ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r bert_no_processing_tokenized_pipeline_model.zip bert_no_processing_tokenized_pipeline_model/"
      ],
      "metadata": {
        "id": "VlFV1sxrZVdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "preds = bert_no_processing_pipeline_model.transform(raw_test_df)\n",
        "\n",
        "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
        "\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
        "\n",
        "print (classification_report(preds_df['category'], preds_df['result']))\n",
        "print(accuracy_score(preds_df['category'], preds_df['result']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSZnR7dWWXbR",
        "outputId": "cbd54bf0-5d89-4c73-a17b-8b455331b668"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business       0.82      0.82      0.82      1900\n",
            "    Sci/Tech       0.83      0.84      0.84      1900\n",
            "      Sports       0.93      0.95      0.94      1900\n",
            "       World       0.90      0.86      0.88      1900\n",
            "\n",
            "    accuracy                           0.87      7600\n",
            "   macro avg       0.87      0.87      0.87      7600\n",
            "weighted avg       0.87      0.87      0.87      7600\n",
            "\n",
            "0.8685526315789474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert w/ Preprocessing"
      ],
      "metadata": {
        "id": "Ms-lDKWmU5Lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B3pvYU4vU5By"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert w/ Stopword Preprocessing"
      ],
      "metadata": {
        "id": "NJgVtAtCp0ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "  \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols([\"normalized\"])\\\n",
        "    .setOutputCol(\"clean_token\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "bert_embeddings = BertEmbeddings().pretrained(name='small_bert_L4_256', lang='en') \\\n",
        "    .setInputCols([\"document\", \"clean_token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "sentence_embedding = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierDL = ClassifierDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"category\")\\\n",
        "    .setMaxEpochs(5)\\\n",
        "    .setLr(0.001)\\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setVerbose(1)\n",
        "\n",
        "\n",
        "bert_stopwords_pipeline = Pipeline(stages=[document_assembler,\n",
        "                                     tokenizer,\n",
        "                                     normalizer,\n",
        "                                     stopwords_cleaner,\n",
        "                                     bert_embeddings,\n",
        "                                     sentence_embedding,\n",
        "                                     classsifierDL])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7JBi4UNRRyG",
        "outputId": "8667d938-1e4f-46cc-f220-21aa74d12f2b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "small_bert_L4_256 download started this may take some time.\n",
            "Approximate size to download 40.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time bert_stopwords_pipeline_model = bert_stopwords_pipeline.fit(raw_train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kue42OAVikXp",
        "outputId": "3109a0a2-48f0-4398-eec4-795d31bdc39b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.94 s, sys: 241 ms, total: 2.19 s\n",
            "Wall time: 7min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_stopwords_pipeline_model.write().overwrite().save('bert_stopwords_pipeline_model')"
      ],
      "metadata": {
        "id": "kG0f-A3fXA_D"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r bert_stopwords_pipeline_model.zip bert_stopwords_pipeline_model/"
      ],
      "metadata": {
        "id": "uLfBjFuiZDuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "preds = bert_stopwords_pipeline_model.transform(raw_test_df)\n",
        "\n",
        "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
        "\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
        "\n",
        "print (classification_report(preds_df['category'], preds_df['result']))\n",
        "print(accuracy_score(preds_df['category'], preds_df['result']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_UNyeUSikTd",
        "outputId": "a98b7c99-d00d-4fb8-9a5d-8689a2358bc4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business       0.82      0.81      0.82      1900\n",
            "    Sci/Tech       0.83      0.86      0.84      1900\n",
            "      Sports       0.94      0.95      0.95      1900\n",
            "       World       0.89      0.86      0.88      1900\n",
            "\n",
            "    accuracy                           0.87      7600\n",
            "   macro avg       0.87      0.87      0.87      7600\n",
            "weighted avg       0.87      0.87      0.87      7600\n",
            "\n",
            "0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert w/ Lemmatized Preprocessing"
      ],
      "metadata": {
        "id": "Vcd-zZ12p9LN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "  \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "      .setInputCols([\"normalized\"]) \\\n",
        "      .setOutputCol(\"lemma\")\n",
        "\n",
        "bert_embeddings = BertEmbeddings().pretrained(name='small_bert_L4_256', lang='en') \\\n",
        "    .setInputCols([\"document\", \"lemma\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "sentence_embedding = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierDL = ClassifierDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"category\")\\\n",
        "    .setMaxEpochs(5)\\\n",
        "    .setLr(0.001)\\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setVerbose(1)\n",
        "\n",
        "\n",
        "bert_lemma_pipeline = Pipeline(stages=[document_assembler,\n",
        "                                     tokenizer,\n",
        "                                     normalizer,\n",
        "                                     lemma,\n",
        "                                     bert_embeddings,\n",
        "                                     sentence_embedding,\n",
        "                                     classsifierDL])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOAL1uw9fze9",
        "outputId": "6fb89d64-cfe8-48f5-8cf6-2a5c63fba559"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n",
            "small_bert_L4_256 download started this may take some time.\n",
            "Approximate size to download 40.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time bert_lemma_pipeline_model = bert_lemma_pipeline.fit(raw_train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwmuBCZfqBB3",
        "outputId": "0827d1f6-233d-49b4-e991-a43192adbc87"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.32 s, sys: 282 ms, total: 2.6 s\n",
            "Wall time: 9min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_lemma_pipeline_model.write().overwrite().save('bert_lemma_pipeline_model')"
      ],
      "metadata": {
        "id": "w7pWZVPngLDB"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r bert_lemma_pipeline_model.zip bert_lemma_pipeline_model/"
      ],
      "metadata": {
        "id": "Mc4KU3DOgkLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "preds = bert_lemma_pipeline_model.transform(raw_test_df)\n",
        "\n",
        "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
        "\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
        "\n",
        "print (classification_report(preds_df['category'], preds_df['result']))\n",
        "print(accuracy_score(preds_df['category'], preds_df['result']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63JtdjZ-qA9P",
        "outputId": "f90fce86-3816-480c-f612-86d87366895d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business       0.82      0.80      0.81      1900\n",
            "    Sci/Tech       0.81      0.85      0.83      1900\n",
            "      Sports       0.93      0.95      0.94      1900\n",
            "       World       0.90      0.85      0.87      1900\n",
            "\n",
            "    accuracy                           0.86      7600\n",
            "   macro avg       0.86      0.86      0.86      7600\n",
            "weighted avg       0.86      0.86      0.86      7600\n",
            "\n",
            "0.8639473684210527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert w/ Stopwords and Lemma Preprocessing"
      ],
      "metadata": {
        "id": "hrYjpvi6gpCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "  \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols([\"normalized\"])\\\n",
        "    .setOutputCol(\"clean_token\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "      .setInputCols([\"clean_token\"]) \\\n",
        "      .setOutputCol(\"lemma\")\n",
        "\n",
        "bert_embeddings = BertEmbeddings().pretrained(name='small_bert_L4_256', lang='en') \\\n",
        "    .setInputCols([\"document\", \"lemma\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "sentence_embedding = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierDL = ClassifierDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"category\")\\\n",
        "    .setMaxEpochs(5)\\\n",
        "    .setLr(0.001)\\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setVerbose(1)\n",
        "\n",
        "\n",
        "bert_stopwords_lemma_pipeline = Pipeline(stages=[document_assembler,\n",
        "                                     tokenizer,\n",
        "                                     normalizer,\n",
        "                                     stopwords_cleaner,\n",
        "                                     lemma,\n",
        "                                     bert_embeddings,\n",
        "                                     sentence_embedding,\n",
        "                                     classsifierDL])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cscm5VCDgodg",
        "outputId": "b40b0f17-cbf8-4c68-ffca-15b2a8878ec8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n",
            "small_bert_L4_256 download started this may take some time.\n",
            "Approximate size to download 40.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time bert_stopwords_lemma_pipeline_model = bert_stopwords_lemma_pipeline.fit(raw_train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekoy9cxWg6_M",
        "outputId": "d6917b0c-a395-4e62-e572-3ea9c42df881"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.19 s, sys: 285 ms, total: 2.48 s\n",
            "Wall time: 8min 9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_stopwords_lemma_pipeline_model.write().overwrite().save('bert_stopwords_lemma_pipeline_model')"
      ],
      "metadata": {
        "id": "Jpae4axpg69C"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r bert_stopwords_lemma_pipeline_model.zip bert_stopwords_lemma_pipeline_model/"
      ],
      "metadata": {
        "id": "-4D5BWaXg66T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "preds = bert_stopwords_lemma_pipeline_model.transform(raw_test_df)\n",
        "\n",
        "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
        "\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
        "\n",
        "print (classification_report(preds_df['category'], preds_df['result']))\n",
        "print(accuracy_score(preds_df['category'], preds_df['result']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB6RbjP-hHmD",
        "outputId": "aff78c16-1aa1-4630-ee4c-07ee9d8c518f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business       0.81      0.82      0.81      1900\n",
            "    Sci/Tech       0.82      0.85      0.84      1900\n",
            "      Sports       0.95      0.94      0.95      1900\n",
            "       World       0.89      0.86      0.88      1900\n",
            "\n",
            "    accuracy                           0.87      7600\n",
            "   macro avg       0.87      0.87      0.87      7600\n",
            "weighted avg       0.87      0.87      0.87      7600\n",
            "\n",
            "0.8681578947368421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roberta"
      ],
      "metadata": {
        "id": "YZL2L0wsU8Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"description\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "  \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols([\"normalized\"])\\\n",
        "    .setOutputCol(\"clean_token\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "      .setInputCols([\"clean_token\"]) \\\n",
        "      .setOutputCol(\"lemma\")\n",
        "\n",
        "roberta_embeddings = RoBertaEmbeddings.pretrained(\"roberta_embeddings_distilroberta_base\",lang=\"en\") \\\n",
        "    .setInputCols([\"document\", \"lemma\"]) \\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "sentence_embedding = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierDL = ClassifierDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"category\")\\\n",
        "    .setMaxEpochs(5)\\\n",
        "    .setLr(0.001)\\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setVerbose(1)\n",
        "\n",
        "\n",
        "roberta_pipeline = Pipeline(stages=[document_assembler,\n",
        "                                     tokenizer,\n",
        "                                     normalizer,\n",
        "                                     stopwords_cleaner,\n",
        "                                     lemma,\n",
        "                                     roberta_embeddings,\n",
        "                                     sentence_embedding,\n",
        "                                     classsifierDL])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP6PmzfhU77N",
        "outputId": "b575bd92-9930-400e-bce0-2a618e90aa07"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n",
            "roberta_embeddings_distilroberta_base download started this may take some time.\n",
            "Approximate size to download 294.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%time roberta_pipeline_model = roberta_pipeline.fit(raw_train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH21-diPU1lk",
        "outputId": "f7920574-786b-4d12-f2eb-f57342b46a14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.14 s, sys: 949 ms, total: 9.09 s\n",
            "Wall time: 31min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roberta_pipeline_model.write().overwrite().save('roberta_pipeline_model')"
      ],
      "metadata": {
        "id": "89Lvx27qliB7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r roberta_pipeline_model.zip roberta_pipeline_model/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-hyFPTylh9Z",
        "outputId": "e59c0a1e-c96c-4ac8-ccfd-6f689d58208e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: roberta_pipeline_model/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/metadata/part-00000 (deflated 26%)\n",
            "  adding: roberta_pipeline_model/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/metadata/part-00000 (deflated 40%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/.roberta_tensorflow.crc (deflated 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/signatures/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/signatures/part-00000 (deflated 33%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/signatures/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/signatures/part-00001 (deflated 26%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/signatures/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/signatures/.part-00001.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/signatures/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/merges/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/merges/part-00000 (deflated 79%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/merges/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/merges/part-00001 (deflated 79%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/merges/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/merges/.part-00001.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/merges/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/vocabulary/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/vocabulary/part-00000 (deflated 78%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/vocabulary/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/vocabulary/part-00001 (deflated 78%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/vocabulary/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/vocabulary/.part-00001.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/fields/vocabulary/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/5_ROBERTA_EMBEDDINGS_7db024986e8d/roberta_tensorflow (deflated 8%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/metadata/part-00000 (deflated 44%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/fields/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/fields/rules/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/fields/rules/part-00000 (deflated 26%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/fields/rules/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/fields/rules/part-00001 (deflated 62%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/fields/rules/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/fields/rules/.part-00001.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/1_REGEX_TOKENIZER_3cc97e0c225e/fields/rules/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/0_DocumentAssembler_7efad3b89103/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/0_DocumentAssembler_7efad3b89103/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/0_DocumentAssembler_7efad3b89103/metadata/part-00000 (deflated 35%)\n",
            "  adding: roberta_pipeline_model/stages/0_DocumentAssembler_7efad3b89103/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/0_DocumentAssembler_7efad3b89103/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/0_DocumentAssembler_7efad3b89103/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/3_StopWordsCleaner_5c92d423b394/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/3_StopWordsCleaner_5c92d423b394/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/3_StopWordsCleaner_5c92d423b394/metadata/part-00000 (deflated 58%)\n",
            "  adding: roberta_pipeline_model/stages/3_StopWordsCleaner_5c92d423b394/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/3_StopWordsCleaner_5c92d423b394/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/3_StopWordsCleaner_5c92d423b394/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/metadata/part-00000 (deflated 39%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/.classifierdl_tensorflow.crc (deflated 43%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/fields/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/fields/datasetParams/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/fields/datasetParams/part-00000 (deflated 27%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/fields/datasetParams/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/fields/datasetParams/part-00001 (deflated 30%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/fields/datasetParams/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/fields/datasetParams/.part-00001.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/fields/datasetParams/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/7_ClassifierDLModel_08b5dd5c1683/classifierdl_tensorflow (deflated 59%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/metadata/part-00000 (deflated 19%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/fields/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/fields/lemmaDict/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/fields/lemmaDict/part-00000 (deflated 75%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/fields/lemmaDict/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/fields/lemmaDict/part-00001 (deflated 75%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/fields/lemmaDict/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/fields/lemmaDict/.part-00001.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/4_LEMMATIZER_c62ad8f355f9/fields/lemmaDict/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/metadata/part-00000 (deflated 40%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/fields/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/fields/slangDict/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/fields/slangDict/part-00000 (deflated 27%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/fields/slangDict/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/fields/slangDict/part-00001 (deflated 27%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/fields/slangDict/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/fields/slangDict/.part-00001.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/2_NORMALIZER_0633e5c0fc4b/fields/slangDict/.part-00000.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/6_SentenceEmbeddings_9da0aa397e23/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/6_SentenceEmbeddings_9da0aa397e23/metadata/ (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/6_SentenceEmbeddings_9da0aa397e23/metadata/part-00000 (deflated 50%)\n",
            "  adding: roberta_pipeline_model/stages/6_SentenceEmbeddings_9da0aa397e23/metadata/_SUCCESS (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/6_SentenceEmbeddings_9da0aa397e23/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: roberta_pipeline_model/stages/6_SentenceEmbeddings_9da0aa397e23/metadata/.part-00000.crc (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "preds = roberta_pipeline_model.transform(raw_test_df)\n",
        "\n",
        "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
        "\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
        "\n",
        "print (classification_report(preds_df['category'], preds_df['result']))\n",
        "print(accuracy_score(preds_df['category'], preds_df['result']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc0EXtuRlh56",
        "outputId": "8039fbc0-79fb-40e2-f6ee-a78399c23fd7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business       0.83      0.83      0.83      1900\n",
            "    Sci/Tech       0.84      0.86      0.85      1900\n",
            "      Sports       0.93      0.97      0.95      1900\n",
            "       World       0.92      0.85      0.88      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n",
            "0.8777631578947368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "59D24MUclhyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}